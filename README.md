
Helper Data Science codes/ explanations:

1) 1st nb : Training and building neural network based embeddings for Text/Categorical data.
<br>
   link for the Original author's notebook in Kaggle : <a href='https://www.kaggle.com/code/rajmehra03/a-detailed-explanation-of-keras-embedding-layer'> Click here for Raj Merhota's Noteboom on Kaggle </a>

<br><br>
2) Understanding Uplift Modelling (S-learner, X-learner, T-learner), a chat with ChatGPT : <a href="https://chat.openai.com/share/29d5a9f3-4001-46d6-abab-16f4b9ba14cc"> Click to view chat </a>

<br><br>
3) Entity Embeddings for Categorical Variables - a comprehensive notebook using FastAI - <a href="https://github.com/adam-mehdi/EntityEmbeddingsTutorial/tree/main">Click here to view notebook </a>
<br><br>
4) Gradient Based One sided Sampling (GOSS) in LightGBM Aalgorithm which also controls imabalanced datasets (GOSS.md in files)
<br> <br>
5) Bert for Masked LM for training embeddings on any unlabeled text data (fine tuning) :
Link to the <a href=https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/language_modeling.ipynb#scrollTo=Y9TFqDG_3l_e> Notebook </a>
